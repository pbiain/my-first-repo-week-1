{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Integration Patterns - Multi-Provider & Modern Token Management\n",
        "\n",
        "This notebook focuses on practical patterns for production AI applications:\n",
        "\n",
        "1. **Multiple LLM Providers** - Using OpenAI and Anthropic together\n",
        "2. **Provider Fallback** - Backup strategies when one provider fails\n",
        "3. **Modern Token Management** - Direct API usage tracking & streaming with progressive monitoring\n",
        "4. **External Data Enrichment** - Combining APIs with LLM prompts\n",
        "5. **Production Configuration** - Environment-based settings\n",
        "\n",
        "We'll use OpenAI and Anthropic APIs throughout, focusing on **modern token management** using:\n",
        "- **Direct API usage tracking** - Using exact token counts from API responses\n",
        "- **Streaming with progressive tracking** - Real-time token monitoring during streaming"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Learning Goals\n",
        "\n",
        "After this lesson, you will be able to:\n",
        "\n",
        "- [ ] Use multiple LLM providers (OpenAI, Anthropic) in the same application\n",
        "- [ ] Pass outputs from one LLM to another LLM\n",
        "- [ ] Implement provider fallback strategies\n",
        "- [ ] Track token usage using **direct API response data** (most reliable method)\n",
        "- [ ] Monitor token consumption in **real-time during streaming**\n",
        "- [ ] Enrich prompts with external data sources\n",
        "- [ ] Apply production configuration patterns"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Setup\n",
        "\n",
        "Let's import the necessary libraries and set up our clients."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "vscode": {
          "languageId": "bat"
        }
      },
      "source": [
        "!pip install anthropic"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import os\n",
        "import time\n",
        "from openai import OpenAI\n",
        "from anthropic import Anthropic\n",
        "from typing import Optional, Dict, Any, Iterator\n",
        "from dotenv import load_dotenv\n",
        "\n",
        "# Load environment variables\n",
        "load_dotenv()\n",
        "\n",
        "# Initialize clients\n",
        "openai_client = OpenAI(api_key=os.getenv(\"OPENAI_API_KEY\"))\n",
        "anthropic_client = Anthropic(api_key=os.getenv(\"ANTHROPIC_API_KEY\"))\n",
        "\n",
        "# Default models\n",
        "OPENAI_MODEL = \"gpt-4o-mini\"\n",
        "ANTHROPIC_MODEL = \"claude-3-5-sonnet-20241022\"\n",
        "\n",
        "print(\"âœ… Setup complete!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "\n",
        "## 1. Working with Multiple LLM Providers\n",
        "\n",
        "### Why Use Multiple Providers?\n",
        "\n",
        "Different LLM providers have different strengths:\n",
        "- **OpenAI (GPT-4o, GPT-4o-mini)**: Great for general tasks, fast, good structured output\n",
        "- **Anthropic (Claude)**: Excellent for long context, detailed analysis, safety-focused\n",
        "\n",
        "Let's set up helper functions for both providers."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def ask_openai(prompt: str, model: str = OPENAI_MODEL) -> Dict[str, Any]:\n",
        "    \"\"\"\n",
        "    Ask OpenAI a question and return response with usage data.\n",
        "    \n",
        "    Args:\n",
        "        prompt: Question or instruction\n",
        "        model: Model to use\n",
        "    \n",
        "    Returns:\n",
        "        Dictionary with response text and usage information\n",
        "    \"\"\"\n",
        "    response = openai_client.chat.completions.create(\n",
        "        model=model,\n",
        "        messages=[{\"role\": \"user\", \"content\": prompt}]\n",
        "    )\n",
        "    \n",
        "    # Extract usage data directly from API response\n",
        "    usage = response.usage\n",
        "    \n",
        "    return {\n",
        "        \"response\": response.choices[0].message.content,\n",
        "        \"usage\": {\n",
        "            \"prompt_tokens\": usage.prompt_tokens,\n",
        "            \"completion_tokens\": usage.completion_tokens,\n",
        "            \"total_tokens\": usage.total_tokens\n",
        "        }\n",
        "    }\n",
        "\n",
        "def ask_anthropic(prompt: str, model: str = ANTHROPIC_MODEL) -> Dict[str, Any]:\n",
        "    \"\"\"\n",
        "    Ask Anthropic Claude a question and return response with usage data.\n",
        "    \n",
        "    Args:\n",
        "        prompt: Question or instruction\n",
        "        model: Model to use\n",
        "    \n",
        "    Returns:\n",
        "        Dictionary with response text and usage information\n",
        "    \"\"\"\n",
        "    response = anthropic_client.messages.create(\n",
        "        model=model,\n",
        "        max_tokens=1024,\n",
        "        messages=[{\"role\": \"user\", \"content\": prompt}]\n",
        "    )\n",
        "    \n",
        "    # Extract usage data directly from API response\n",
        "    usage = response.usage\n",
        "    \n",
        "    return {\n",
        "        \"response\": response.content[0].text,\n",
        "        \"usage\": {\n",
        "            \"input_tokens\": usage.input_tokens,\n",
        "            \"output_tokens\": usage.output_tokens\n",
        "        }\n",
        "    }\n",
        "\n",
        "print(\"âœ… Provider functions ready! (now with direct API usage tracking)\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Comparing Providers\n",
        "\n",
        "Let's compare responses from both providers:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def compare_providers(prompt: str) -> Dict[str, Any]:\n",
        "    \"\"\"\n",
        "    Ask the same question to both providers and compare responses + token usage.\n",
        "    \n",
        "    Args:\n",
        "        prompt: Question to ask\n",
        "    \n",
        "    Returns:\n",
        "        Dictionary with both responses and usage data\n",
        "    \"\"\"\n",
        "    print(f\"Question: {prompt}\\n\")\n",
        "    \n",
        "    # Ask OpenAI\n",
        "    print(\"Asking OpenAI...\")\n",
        "    openai_result = ask_openai(prompt)\n",
        "    print(f\"OpenAI Response: {openai_result['response']}\")\n",
        "    print(f\"OpenAI Usage: {openai_result['usage']}\\n\")\n",
        "    \n",
        "    # Ask Anthropic\n",
        "    print(\"Asking Anthropic...\")\n",
        "    anthropic_result = ask_anthropic(prompt)\n",
        "    print(f\"Anthropic Response: {anthropic_result['response']}\")\n",
        "    print(f\"Anthropic Usage: {anthropic_result['usage']}\\n\")\n",
        "    \n",
        "    return {\n",
        "        \"openai\": openai_result,\n",
        "        \"anthropic\": anthropic_result\n",
        "    }\n",
        "\n",
        "# Test with a simple prompt\n",
        "# results = compare_providers(\"Explain machine learning in one sentence\")\n",
        "# print(\"âœ… Comparison complete!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Passing Outputs Between Providers\n",
        "\n",
        "One powerful pattern: use one LLM's output as another's input."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def generate_and_review(topic: str) -> Dict[str, Any]:\n",
        "    \"\"\"\n",
        "    Use OpenAI to generate content, then Anthropic to review it.\n",
        "    Tracks token usage from both API calls.\n",
        "    \n",
        "    Args:\n",
        "        topic: Topic to write about\n",
        "    \n",
        "    Returns:\n",
        "        Dictionary with content, review, and usage data\n",
        "    \"\"\"\n",
        "    # Step 1: Generate content with OpenAI\n",
        "    print(f\"Step 1: Generating content about '{topic}' with OpenAI...\")\n",
        "    content_prompt = f\"Write a short paragraph about {topic}\"\n",
        "    openai_result = ask_openai(content_prompt)\n",
        "    content = openai_result['response']\n",
        "    print(f\"Content: {content}\")\n",
        "    print(f\"OpenAI Usage: {openai_result['usage']}\\n\")\n",
        "    \n",
        "    # Step 2: Review with Anthropic\n",
        "    print(\"Step 2: Reviewing with Anthropic...\")\n",
        "    review_prompt = f\"\"\"Review this paragraph and provide feedback:\n",
        "\n",
        "{content}\n",
        "\n",
        "Provide:\n",
        "1. What's good about it\n",
        "2. What could be improved\n",
        "3. A rating out of 10\"\"\"\n",
        "    \n",
        "    anthropic_result = ask_anthropic(review_prompt)\n",
        "    review = anthropic_result['response']\n",
        "    print(f\"Review: {review}\")\n",
        "    print(f\"Anthropic Usage: {anthropic_result['usage']}\\n\")\n",
        "    \n",
        "    return {\n",
        "        \"topic\": topic,\n",
        "        \"content\": content,\n",
        "        \"review\": review,\n",
        "        \"usage\": {\n",
        "            \"openai\": openai_result['usage'],\n",
        "            \"anthropic\": anthropic_result['usage']\n",
        "        }\n",
        "    }\n",
        "\n",
        "# Test (commented out to avoid API calls)\n",
        "# result = generate_and_review(\"artificial intelligence\")\n",
        "# print(\"âœ… Generate and review complete!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "\n",
        "## 2. Provider Fallback Patterns\n",
        "\n",
        "What happens when one provider fails or is rate-limited? You need a backup."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def ask_with_fallback(prompt: str, primary: str = \"openai\", secondary: str = \"anthropic\") -> Dict[str, Any]:\n",
        "    \"\"\"\n",
        "    Try primary provider first, fall back to secondary if it fails.\n",
        "    Returns usage data from whichever provider succeeded.\n",
        "    \n",
        "    Args:\n",
        "        prompt: Question to ask\n",
        "        primary: Primary provider to try first\n",
        "        secondary: Backup provider\n",
        "    \n",
        "    Returns:\n",
        "        Response and usage data from whichever provider succeeded\n",
        "    \"\"\"\n",
        "    # Try primary provider\n",
        "    try:\n",
        "        if primary == \"openai\":\n",
        "            print(\"Trying OpenAI (primary)...\")\n",
        "            result = ask_openai(prompt)\n",
        "            print(\"âœ“ OpenAI succeeded\")\n",
        "            return {\n",
        "                \"provider\": \"openai\",\n",
        "                \"response\": result[\"response\"],\n",
        "                \"usage\": result[\"usage\"]\n",
        "            }\n",
        "    \n",
        "    except Exception as e:\n",
        "        print(f\"âœ— OpenAI failed: {e}\")\n",
        "        print(f\"Falling back to {secondary}...\")\n",
        "    \n",
        "    # If primary failed, try secondary\n",
        "    try:\n",
        "        if secondary == \"anthropic\":\n",
        "            print(\"Trying Anthropic (fallback)...\")\n",
        "            result = ask_anthropic(prompt)\n",
        "            print(\"âœ“ Anthropic succeeded\")\n",
        "            return {\n",
        "                \"provider\": \"anthropic\",\n",
        "                \"response\": result[\"response\"],\n",
        "                \"usage\": result[\"usage\"]\n",
        "            }\n",
        "    \n",
        "    except Exception as e:\n",
        "        print(f\"âœ— Anthropic also failed: {e}\")\n",
        "        raise Exception(\"All providers failed\")\n",
        "\n",
        "# Test (commented out)\n",
        "# result = ask_with_fallback(\"What is machine learning?\")\n",
        "# print(f\"\\nUsed provider: {result['provider']}\")\n",
        "# print(f\"Response: {result['response'][:100]}...\")\n",
        "# print(f\"Usage: {result['usage']}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "\n",
        "## 3. Modern Token Management\n",
        "\n",
        "Modern token management uses **direct API usage tracking** - the most reliable method. Instead of estimating tokens before API calls, we use the exact token counts returned by the API responses. This is more accurate and eliminates estimation errors.\n",
        "\n",
        "We'll also explore **streaming with progressive tracking** to monitor token consumption in real-time."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Direct API Usage Tracking\n",
        "\n",
        "**Key Principle**: Use the exact token counts from API responses, not estimates.\n",
        "\n",
        "Both OpenAI and Anthropic APIs return usage information in their responses. This is the most reliable method because:\n",
        "1. **Accuracy**: The API knows exactly how many tokens were used\n",
        "2. **No estimation errors**: No need to guess or approximate\n",
        "3. **Model-specific**: Works correctly for all models without special handling"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Example: Direct API usage tracking\n",
        "# When you make an API call, the response includes exact token counts\n",
        "\n",
        "example_prompt = \"Explain machine learning in one sentence\"\n",
        "\n",
        "print(\"Example: Getting exact token counts from API response\")\n",
        "print(\"=\" * 60)\n",
        "\n",
        "# OpenAI returns usage in response.usage\n",
        "print(\"\\nOpenAI API Response Structure:\")\n",
        "print(\"- response.usage.prompt_tokens    (input tokens)\")\n",
        "print(\"- response.usage.completion_tokens (output tokens)\")\n",
        "print(\"- response.usage.total_tokens     (total)\")\n",
        "\n",
        "# Anthropic returns usage in response.usage\n",
        "print(\"\\nAnthropic API Response Structure:\")\n",
        "print(\"- response.usage.input_tokens     (input tokens)\")\n",
        "print(\"- response.usage.output_tokens   (output tokens)\")\n",
        "\n",
        "print(\"\\nâœ… No estimation needed - use the exact counts from API responses!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Token Budget Manager\n",
        "\n",
        "Now let's create a token budget manager that tracks usage across providers:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "class TokenBudgetManager:\n",
        "    \"\"\"Manage token budgets using direct API usage data.\"\"\"\n",
        "    \n",
        "    def __init__(self, daily_budget: float = 100.0):\n",
        "        \"\"\"\n",
        "        Initialize token budget manager.\n",
        "        \n",
        "        Args:\n",
        "            daily_budget: Daily budget in dollars\n",
        "        \"\"\"\n",
        "        self.daily_budget = daily_budget\n",
        "        self.used_budget = 0.0\n",
        "        self.provider_usage = {\n",
        "            \"openai\": {\"input_tokens\": 0, \"output_tokens\": 0, \"cost\": 0.0},\n",
        "            \"anthropic\": {\"input_tokens\": 0, \"output_tokens\": 0, \"cost\": 0.0}\n",
        "        }\n",
        "        \n",
        "        # Pricing per 1M tokens (as of 2026-01)\n",
        "        self.pricing = {\n",
        "            \"openai\": {\n",
        "                \"gpt-4o-mini\": {\"input\": 0.15 / 1_000_000, \"output\": 0.60 / 1_000_000},\n",
        "                \"gpt-4o\": {\"input\": 2.50 / 1_000_000, \"output\": 10.00 / 1_000_000}\n",
        "            },\n",
        "            \"anthropic\": {\n",
        "                \"claude-3-5-sonnet-20241022\": {\"input\": 3.00 / 1_000_000, \"output\": 15.00 / 1_000_000}\n",
        "            }\n",
        "        }\n",
        "    \n",
        "    def calculate_cost(self, provider: str, model: str, input_tokens: int, output_tokens: int) -> float:\n",
        "        \"\"\"\n",
        "        Calculate cost for a request using exact token counts.\n",
        "        \n",
        "        Args:\n",
        "            provider: Provider name (\"openai\" or \"anthropic\")\n",
        "            model: Model name\n",
        "            input_tokens: Number of input tokens (from API response)\n",
        "            output_tokens: Number of output tokens (from API response)\n",
        "        \n",
        "        Returns:\n",
        "            Cost in dollars\n",
        "        \"\"\"\n",
        "        if provider not in self.pricing:\n",
        "            return 0.0\n",
        "        \n",
        "        if model not in self.pricing[provider]:\n",
        "            return 0.0\n",
        "        \n",
        "        pricing = self.pricing[provider][model]\n",
        "        input_cost = input_tokens * pricing[\"input\"]\n",
        "        output_cost = output_tokens * pricing[\"output\"]\n",
        "        return input_cost + output_cost\n",
        "    \n",
        "    def track_request(self, provider: str, model: str, input_tokens: int, output_tokens: int) -> Dict[str, Any]:\n",
        "        \"\"\"\n",
        "        Track a request using exact token counts from API response.\n",
        "        \n",
        "        Args:\n",
        "            provider: Provider name\n",
        "            model: Model name\n",
        "            input_tokens: Exact input tokens from API response\n",
        "            output_tokens: Exact output tokens from API response\n",
        "        \n",
        "        Returns:\n",
        "            Dictionary with cost and budget status\n",
        "        \"\"\"\n",
        "        cost = self.calculate_cost(provider, model, input_tokens, output_tokens)\n",
        "        \n",
        "        # Check if we're over budget\n",
        "        if self.used_budget + cost > self.daily_budget:\n",
        "            remaining = self.daily_budget - self.used_budget\n",
        "            raise Exception(\n",
        "                f\"Token budget exceeded! \"\n",
        "                f\"Request cost ${cost:.6f}, but only ${remaining:.6f} remaining. \"\n",
        "                f\"Daily budget: ${self.daily_budget:.2f}\"\n",
        "            )\n",
        "        \n",
        "        # Update usage with exact counts\n",
        "        self.used_budget += cost\n",
        "        if provider in self.provider_usage:\n",
        "            self.provider_usage[provider][\"input_tokens\"] += input_tokens\n",
        "            self.provider_usage[provider][\"output_tokens\"] += output_tokens\n",
        "            self.provider_usage[provider][\"cost\"] += cost\n",
        "        \n",
        "        return {\n",
        "            \"cost\": cost,\n",
        "            \"remaining_budget\": self.daily_budget - self.used_budget,\n",
        "            \"budget_used_percent\": (self.used_budget / self.daily_budget) * 100\n",
        "        }\n",
        "    \n",
        "    def get_summary(self) -> Dict[str, Any]:\n",
        "        \"\"\"Get budget summary.\"\"\"\n",
        "        return {\n",
        "            \"daily_budget\": self.daily_budget,\n",
        "            \"used_budget\": self.used_budget,\n",
        "            \"remaining_budget\": self.daily_budget - self.used_budget,\n",
        "            \"budget_used_percent\": (self.used_budget / self.daily_budget) * 100,\n",
        "            \"provider_usage\": self.provider_usage\n",
        "        }\n",
        "    \n",
        "    def print_summary(self):\n",
        "        \"\"\"Print budget summary.\"\"\"\n",
        "        summary = self.get_summary()\n",
        "        print(\"\\n\" + \"=\" * 60)\n",
        "        print(\"TOKEN BUDGET SUMMARY\")\n",
        "        print(\"=\" * 60)\n",
        "        print(f\"Daily Budget: ${summary['daily_budget']:.2f}\")\n",
        "        print(f\"Used: ${summary['used_budget']:.4f} ({summary['budget_used_percent']:.1f}%)\")\n",
        "        print(f\"Remaining: ${summary['remaining_budget']:.4f}\")\n",
        "        print(\"\\nProvider Breakdown:\")\n",
        "        for provider, usage in summary['provider_usage'].items():\n",
        "            if usage['input_tokens'] > 0 or usage['output_tokens'] > 0:\n",
        "                print(f\"\\n  {provider.upper()}:\")\n",
        "                print(f\"    Input tokens: {usage['input_tokens']:,}\")\n",
        "                print(f\"    Output tokens: {usage['output_tokens']:,}\")\n",
        "                print(f\"    Total cost: ${usage['cost']:.4f}\")\n",
        "        print(\"=\" * 60)\n",
        "\n",
        "# Create a budget manager\n",
        "budget_manager = TokenBudgetManager(daily_budget=10.0)\n",
        "print(\"âœ… Token budget manager ready!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def ask_openai_with_budget(\n",
        "    prompt: str,\n",
        "    model: str = OPENAI_MODEL,\n",
        "    budget_manager: TokenBudgetManager = None\n",
        ") -> Dict[str, Any]:\n",
        "    \"\"\"\n",
        "    Ask OpenAI with token budget tracking using DIRECT API usage data.\n",
        "    \n",
        "    Modern approach: Use exact token counts from API response, not estimates.\n",
        "    \n",
        "    Args:\n",
        "        prompt: Question to ask\n",
        "        model: Model to use\n",
        "        budget_manager: TokenBudgetManager instance\n",
        "    \n",
        "    Returns:\n",
        "        Dictionary with response and budget info\n",
        "    \"\"\"\n",
        "    # Make API call - get response with usage data\n",
        "    result = ask_openai(prompt, model)\n",
        "    \n",
        "    # Extract exact token counts from API response\n",
        "    input_tokens = result['usage']['prompt_tokens']\n",
        "    output_tokens = result['usage']['completion_tokens']\n",
        "    \n",
        "    # Track with budget manager using exact counts\n",
        "    if budget_manager:\n",
        "        budget_info = budget_manager.track_request(\n",
        "            provider=\"openai\",\n",
        "            model=model,\n",
        "            input_tokens=input_tokens,\n",
        "            output_tokens=output_tokens\n",
        "        )\n",
        "        print(f\"ðŸ’° Tokens: {input_tokens} input + {output_tokens} output = {result['usage']['total_tokens']} total\")\n",
        "        print(f\"   Cost: ${budget_info['cost']:.6f} (${budget_info['remaining_budget']:.4f} remaining)\")\n",
        "    \n",
        "    return {\n",
        "        \"response\": result['response'],\n",
        "        \"usage\": result['usage'],\n",
        "        \"provider\": \"openai\",\n",
        "        \"model\": model\n",
        "    }\n",
        "\n",
        "def ask_anthropic_with_budget(\n",
        "    prompt: str,\n",
        "    model: str = ANTHROPIC_MODEL,\n",
        "    budget_manager: TokenBudgetManager = None\n",
        ") -> Dict[str, Any]:\n",
        "    \"\"\"\n",
        "    Ask Anthropic with token budget tracking using DIRECT API usage data.\n",
        "    \n",
        "    Modern approach: Use exact token counts from API response, not estimates.\n",
        "    \n",
        "    Args:\n",
        "        prompt: Question to ask\n",
        "        model: Model to use\n",
        "        budget_manager: TokenBudgetManager instance\n",
        "    \n",
        "    Returns:\n",
        "        Dictionary with response and budget info\n",
        "    \"\"\"\n",
        "    # Make API call - get response with usage data\n",
        "    result = ask_anthropic(prompt, model)\n",
        "    \n",
        "    # Extract exact token counts from API response\n",
        "    input_tokens = result['usage']['input_tokens']\n",
        "    output_tokens = result['usage']['output_tokens']\n",
        "    \n",
        "    # Track with budget manager using exact counts\n",
        "    if budget_manager:\n",
        "        budget_info = budget_manager.track_request(\n",
        "            provider=\"anthropic\",\n",
        "            model=model,\n",
        "            input_tokens=input_tokens,\n",
        "            output_tokens=output_tokens\n",
        "        )\n",
        "        print(f\"ðŸ’° Tokens: {input_tokens} input + {output_tokens} output\")\n",
        "        print(f\"   Cost: ${budget_info['cost']:.6f} (${budget_info['remaining_budget']:.4f} remaining)\")\n",
        "    \n",
        "    return {\n",
        "        \"response\": result['response'],\n",
        "        \"usage\": result['usage'],\n",
        "        \"provider\": \"anthropic\",\n",
        "        \"model\": model\n",
        "    }\n",
        "\n",
        "print(\"âœ… Budget-aware API functions ready! (using direct API usage tracking)\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Streaming with Progressive Token Tracking\n",
        "\n",
        "**Key Principle**: Monitor token consumption in real-time during streaming to cut off requests that exceed budgets before they finish.\n",
        "\n",
        "When streaming responses, you can track tokens progressively as they arrive, allowing you to:\n",
        "1. Monitor consumption in real-time\n",
        "2. Stop requests early if they exceed budget\n",
        "3. Provide better user experience with streaming"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def ask_openai_streaming(\n",
        "    prompt: str,\n",
        "    model: str = OPENAI_MODEL,\n",
        "    budget_manager: TokenBudgetManager = None,\n",
        "    max_output_tokens: Optional[int] = None\n",
        ") -> Iterator[Dict[str, Any]]:\n",
        "    \"\"\"\n",
        "    Stream OpenAI response with progressive token tracking.\n",
        "    \n",
        "    Args:\n",
        "        prompt: Question to ask\n",
        "        model: Model to use\n",
        "        budget_manager: TokenBudgetManager instance\n",
        "        max_output_tokens: Optional limit on output tokens\n",
        "    \n",
        "    Yields:\n",
        "        Dictionary with chunk text and current usage stats\n",
        "    \"\"\"\n",
        "    # Create streaming request\n",
        "    stream = openai_client.chat.completions.create(\n",
        "        model=model,\n",
        "        messages=[{\"role\": \"user\", \"content\": prompt}],\n",
        "        stream=True\n",
        "    )\n",
        "    \n",
        "    full_response = \"\"\n",
        "    input_tokens = None\n",
        "    output_tokens = 0\n",
        "    \n",
        "    for chunk in stream:\n",
        "        # Extract delta content\n",
        "        if chunk.choices[0].delta.content:\n",
        "            content = chunk.choices[0].delta.content\n",
        "            full_response += content\n",
        "            \n",
        "            # Track output tokens progressively (approximate: ~4 chars per token)\n",
        "            # Note: For exact counts, wait for final usage data\n",
        "            output_tokens_approx = len(full_response) // 4\n",
        "            \n",
        "            # Check budget during streaming\n",
        "            if budget_manager and input_tokens is not None:\n",
        "                estimated_cost = budget_manager.calculate_cost(\n",
        "                    \"openai\", model, input_tokens, output_tokens_approx\n",
        "                )\n",
        "                if budget_manager.used_budget + estimated_cost > budget_manager.daily_budget:\n",
        "                    print(f\"\\nâš ï¸  Budget limit approaching! Stopping stream.\")\n",
        "                    break\n",
        "            \n",
        "            # Check max output tokens\n",
        "            if max_output_tokens and output_tokens_approx >= max_output_tokens:\n",
        "                print(f\"\\nâš ï¸  Max output tokens reached ({max_output_tokens}). Stopping stream.\")\n",
        "                break\n",
        "        \n",
        "        # Get usage data when available (in final chunk)\n",
        "        if chunk.usage:\n",
        "            input_tokens = chunk.usage.prompt_tokens\n",
        "            output_tokens = chunk.usage.completion_tokens\n",
        "            \n",
        "            # Final budget tracking with exact counts\n",
        "            if budget_manager:\n",
        "                budget_info = budget_manager.track_request(\n",
        "                    provider=\"openai\",\n",
        "                    model=model,\n",
        "                    input_tokens=input_tokens,\n",
        "                    output_tokens=output_tokens\n",
        "                )\n",
        "                yield {\n",
        "                    \"type\": \"usage\",\n",
        "                    \"usage\": {\n",
        "                        \"prompt_tokens\": input_tokens,\n",
        "                        \"completion_tokens\": output_tokens,\n",
        "                        \"total_tokens\": chunk.usage.total_tokens\n",
        "                    },\n",
        "                    \"budget_info\": budget_info\n",
        "                }\n",
        "        \n",
        "        # Yield content chunk\n",
        "        if chunk.choices[0].delta.content:\n",
        "            yield {\n",
        "                \"type\": \"content\",\n",
        "                \"content\": chunk.choices[0].delta.content,\n",
        "                \"full_response\": full_response,\n",
        "                \"estimated_tokens\": output_tokens_approx if 'output_tokens_approx' in locals() else 0\n",
        "            }\n",
        "\n",
        "def ask_anthropic_streaming(\n",
        "    prompt: str,\n",
        "    model: str = ANTHROPIC_MODEL,\n",
        "    budget_manager: TokenBudgetManager = None,\n",
        "    max_output_tokens: Optional[int] = None\n",
        ") -> Iterator[Dict[str, Any]]:\n",
        "    \"\"\"\n",
        "    Stream Anthropic response with progressive token tracking.\n",
        "    \n",
        "    Args:\n",
        "        prompt: Question to ask\n",
        "        model: Model to use\n",
        "        budget_manager: TokenBudgetManager instance\n",
        "        max_output_tokens: Optional limit on output tokens\n",
        "    \n",
        "    Yields:\n",
        "        Dictionary with chunk text and current usage stats\n",
        "    \"\"\"\n",
        "    # Create streaming request\n",
        "    with anthropic_client.messages.stream(\n",
        "        model=model,\n",
        "        max_tokens=1024,\n",
        "        messages=[{\"role\": \"user\", \"content\": prompt}]\n",
        "    ) as stream:\n",
        "        full_response = \"\"\n",
        "        input_tokens = None\n",
        "        output_tokens = 0\n",
        "        \n",
        "        for text_event in stream.text_stream:\n",
        "            if text_event:\n",
        "                full_response += text_event\n",
        "                \n",
        "                # Track output tokens progressively (approximate)\n",
        "                output_tokens_approx = len(full_response) // 4\n",
        "                \n",
        "                # Check budget during streaming\n",
        "                if budget_manager and input_tokens is not None:\n",
        "                    estimated_cost = budget_manager.calculate_cost(\n",
        "                        \"anthropic\", model, input_tokens, output_tokens_approx\n",
        "                    )\n",
        "                    if budget_manager.used_budget + estimated_cost > budget_manager.daily_budget:\n",
        "                        print(f\"\\nâš ï¸  Budget limit approaching! Stopping stream.\")\n",
        "                        break\n",
        "                \n",
        "                # Check max output tokens\n",
        "                if max_output_tokens and output_tokens_approx >= max_output_tokens:\n",
        "                    print(f\"\\nâš ï¸  Max output tokens reached ({max_output_tokens}). Stopping stream.\")\n",
        "                    break\n",
        "                \n",
        "                yield {\n",
        "                    \"type\": \"content\",\n",
        "                    \"content\": text_event,\n",
        "                    \"full_response\": full_response,\n",
        "                    \"estimated_tokens\": output_tokens_approx\n",
        "                }\n",
        "        \n",
        "        # Get final usage data\n",
        "        message = stream.get_final_message()\n",
        "        if message.usage:\n",
        "            input_tokens = message.usage.input_tokens\n",
        "            output_tokens = message.usage.output_tokens\n",
        "            \n",
        "            # Final budget tracking with exact counts\n",
        "            if budget_manager:\n",
        "                budget_info = budget_manager.track_request(\n",
        "                    provider=\"anthropic\",\n",
        "                    model=model,\n",
        "                    input_tokens=input_tokens,\n",
        "                    output_tokens=output_tokens\n",
        "                )\n",
        "                yield {\n",
        "                    \"type\": \"usage\",\n",
        "                    \"usage\": {\n",
        "                        \"input_tokens\": input_tokens,\n",
        "                        \"output_tokens\": output_tokens\n",
        "                    },\n",
        "                    \"budget_info\": budget_info\n",
        "                }\n",
        "\n",
        "print(\"âœ… Streaming functions with progressive tracking ready!\")\n",
        "\n",
        "# Example usage (commented out):\n",
        "# print(\"\\nExample: Streaming with progressive tracking\")\n",
        "# print(\"=\" * 60)\n",
        "# for chunk in ask_openai_streaming(\"Write a short story about AI\", budget_manager=budget_manager):\n",
        "#     if chunk[\"type\"] == \"content\":\n",
        "#         print(chunk[\"content\"], end=\"\", flush=True)\n",
        "#     elif chunk[\"type\"] == \"usage\":\n",
        "#         print(f\"\\n\\nðŸ“Š Final Usage: {chunk['usage']}\")\n",
        "#         print(f\"ðŸ’° Budget: {chunk['budget_info']}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Create a test budget manager with a small budget\n",
        "test_budget = TokenBudgetManager(daily_budget=0.0010)  # $0.10 for testing\n",
        "\n",
        "print(\"Testing token budget system:\")\n",
        "print(\"=\" * 60)\n",
        "\n",
        "# Test 1: Make a request within budget\n",
        "try:\n",
        "    print(\"\\n--- Test 1: Request within budget ---\")\n",
        "    result = ask_openai_with_budget(\n",
        "        \"Say hello in one sentence.\",\n",
        "        model=\"gpt-4o-mini\",\n",
        "        budget_manager=test_budget\n",
        "    )\n",
        "    print(f\"Response: {result['response']}\")\n",
        "    print(f\"Tokens: {result['input_tokens']} input + {result['output_tokens']} output\")\n",
        "except Exception as e:\n",
        "    print(f\"Error: {e}\")\n",
        "\n",
        "# Show budget status\n",
        "test_budget.print_summary()\n",
        "\n",
        "# Test 2: Try to exceed budget\n",
        "print(\"\\n--- Test 2: Attempting to exceed budget ---\")\n",
        "try:\n",
        "    # Try to make many requests to exceed budget\n",
        "    for i in range(100):\n",
        "        result = ask_openai_with_budget(\n",
        "            f\"Count to {i}\",\n",
        "            model=\"gpt-4o-mini\",\n",
        "            budget_manager=test_budget\n",
        "        )\n",
        "        print(f\"Request {i+1} succeeded\")\n",
        "except Exception as e:\n",
        "    print(f\"Budget limit reached: {e}\")\n",
        "\n",
        "test_budget.print_summary()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "\n",
        "## 4. Enriching Prompts with External Data\n",
        "\n",
        "LLMs have knowledge cutoffs. Fetch external data and add it to prompts for real-time information."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import requests\n",
        "from typing import Optional\n",
        "\n",
        "def fetch_weather_data(city: str, api_key: Optional[str] = None) -> Optional[Dict[str, Any]]:\n",
        "    \"\"\"\n",
        "    Fetch current weather data for a city (mock implementation).\n",
        "    \n",
        "    Args:\n",
        "        city: City name\n",
        "        api_key: API key (optional for demo)\n",
        "    \n",
        "    Returns:\n",
        "        Weather data dictionary or None\n",
        "    \"\"\"\n",
        "    # This is a mock implementation\n",
        "    # In production, you'd use a real weather API like OpenWeatherMap\n",
        "    \n",
        "    # Mock data for demonstration\n",
        "    mock_weather = {\n",
        "        \"city\": city,\n",
        "        \"temperature\": 22.5,\n",
        "        \"feels_like\": 21.0,\n",
        "        \"description\": \"partly cloudy\",\n",
        "        \"humidity\": 65,\n",
        "        \"wind_speed\": 5.2\n",
        "    }\n",
        "    \n",
        "    print(f\"ðŸŒ¤ï¸  Fetching weather for {city}...\")\n",
        "    print(f\"   Temperature: {mock_weather['temperature']}Â°C\")\n",
        "    print(f\"   Conditions: {mock_weather['description']}\")\n",
        "    \n",
        "    return mock_weather\n",
        "\n",
        "def get_weather_advice(city: str, budget_manager: TokenBudgetManager = None) -> Dict[str, Any]:\n",
        "    \"\"\"\n",
        "    Fetch weather data and ask LLM for advice.\n",
        "    \n",
        "    Args:\n",
        "        city: City name\n",
        "        budget_manager: Optional token budget manager\n",
        "    \n",
        "    Returns:\n",
        "        Weather advice from LLM\n",
        "    \"\"\"\n",
        "    # Step 1: Fetch external data\n",
        "    weather = fetch_weather_data(city)\n",
        "    \n",
        "    if not weather:\n",
        "        return {\"error\": \"Couldn't fetch weather data\"}\n",
        "    \n",
        "    # Step 2: Create prompt with the data\n",
        "    prompt = f\"\"\"Based on this current weather in {weather['city']}:\n",
        "\n",
        "Temperature: {weather['temperature']}Â°C (feels like {weather['feels_like']}Â°C)\n",
        "Conditions: {weather['description']}\n",
        "Humidity: {weather['humidity']}%\n",
        "Wind speed: {weather['wind_speed']} m/s\n",
        "\n",
        "Give practical advice for someone going out today. What should they wear? Any precautions?\"\"\"\n",
        "    \n",
        "    # Step 3: Ask LLM with enriched prompt\n",
        "    print(\"\\nðŸ¤– Asking LLM for advice...\")\n",
        "    if budget_manager:\n",
        "        result = ask_openai_with_budget(prompt, budget_manager=budget_manager)\n",
        "        advice = result['response']\n",
        "    else:\n",
        "        advice = ask_openai(prompt)\n",
        "    \n",
        "    return {\n",
        "        \"city\": city,\n",
        "        \"weather\": weather,\n",
        "        \"advice\": advice\n",
        "    }\n",
        "\n",
        "# Test (commented out)\n",
        "# result = get_weather_advice(\"London\", budget_manager=budget_manager)\n",
        "# print(f\"\\nðŸ’¡ Advice: {result['advice']}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "\n",
        "## 5. Production Configuration\n",
        "\n",
        "Manage API keys, environments, and settings properly."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "class Config:\n",
        "    \"\"\"Configuration for different environments.\"\"\"\n",
        "    \n",
        "    def __init__(self, environment: Optional[str] = None):\n",
        "        if environment is None:\n",
        "            environment = os.getenv(\"ENVIRONMENT\", \"development\")\n",
        "        \n",
        "        self.environment = environment\n",
        "        self.load_config()\n",
        "    \n",
        "    def load_config(self):\n",
        "        \"\"\"Load configuration based on environment.\"\"\"\n",
        "        if self.environment == \"production\":\n",
        "            self.debug = False\n",
        "            self.max_retries = 5\n",
        "            self.timeout = 60\n",
        "            self.log_level = \"INFO\"\n",
        "            self.use_cache = True\n",
        "            self.openai_model = \"gpt-4o\"\n",
        "            self.daily_budget = float(os.getenv(\"DAILY_BUDGET\", \"100.0\"))\n",
        "        \n",
        "        elif self.environment == \"staging\":\n",
        "            self.debug = True\n",
        "            self.max_retries = 3\n",
        "            self.timeout = 30\n",
        "            self.log_level = \"DEBUG\"\n",
        "            self.use_cache = True\n",
        "            self.openai_model = \"gpt-4o-mini\"\n",
        "            self.daily_budget = float(os.getenv(\"DAILY_BUDGET\", \"10.0\"))\n",
        "        \n",
        "        else:  # development\n",
        "            self.debug = True\n",
        "            self.max_retries = 2\n",
        "            self.timeout = 10\n",
        "            self.log_level = \"DEBUG\"\n",
        "            self.use_cache = False\n",
        "            self.openai_model = \"gpt-4o-mini\"\n",
        "            self.daily_budget = float(os.getenv(\"DAILY_BUDGET\", \"1.0\"))\n",
        "    \n",
        "    def get_budget_manager(self) -> TokenBudgetManager:\n",
        "        \"\"\"Get configured budget manager.\"\"\"\n",
        "        return TokenBudgetManager(daily_budget=self.daily_budget)\n",
        "\n",
        "# Usage\n",
        "config = Config()\n",
        "print(f\"Environment: {config.environment}\")\n",
        "print(f\"Debug mode: {config.debug}\")\n",
        "print(f\"Using model: {config.openai_model}\")\n",
        "print(f\"Daily budget: ${config.daily_budget:.2f}\")\n",
        "\n",
        "# Get budget manager with correct configuration\n",
        "budget_manager = config.get_budget_manager()\n",
        "print(\"âœ… Configuration loaded!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "\n",
        "## Summary\n",
        "\n",
        "You've learned practical patterns for production AI applications:\n",
        "\n",
        "### Multiple LLM Providers\n",
        "- âœ… Using OpenAI and Anthropic together\n",
        "- âœ… Passing outputs between providers\n",
        "- âœ… Comparing responses from different models\n",
        "\n",
        "### Provider Fallback\n",
        "- âœ… Automatic fallback when primary provider fails\n",
        "- âœ… Cost-based provider selection\n",
        "\n",
        "### Token Budgets\n",
        "- âœ… Accurate token counting for different models\n",
        "- âœ… Budget tracking across providers\n",
        "- âœ… Cost calculation and budget enforcement\n",
        "- âœ… Smart routing based on remaining budget\n",
        "\n",
        "### External Data Enrichment\n",
        "- âœ… Fetching data from external APIs\n",
        "- âœ… Injecting data into prompts\n",
        "- âœ… Real-time information for LLMs\n",
        "\n",
        "### Production Configuration\n",
        "- âœ… Environment-based settings\n",
        "- âœ… Secure API key management\n",
        "- âœ… Configurable budgets per environment\n",
        "\n",
        "**Key Takeaways:**\n",
        "\n",
        "1. **Use multiple providers** - Different models excel at different tasks\n",
        "2. **Track token budgets** - Prevent cost overruns with budget management\n",
        "3. **Enrich with data** - Combine LLMs with real-time external data\n",
        "4. **Plan for failures** - Always have fallback strategies\n",
        "5. **Configure per environment** - Different settings for dev/staging/prod\n",
        "\n",
        "**Next Steps:**\n",
        "- Practice implementing these patterns in your own projects\n",
        "- Experiment with different budget thresholds\n",
        "- Try combining multiple data sources\n",
        "- Monitor token usage in production"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Exercises\n",
        "\n",
        "Try these exercises to solidify your understanding:\n",
        "\n",
        "1. **Budget Alerts**: Add alert thresholds (e.g., warn at 50%, 75%, 90% of budget)\n",
        "\n",
        "2. **Multi-Provider Chain**: Build a pipeline that uses OpenAI for generation, Anthropic for review, and tracks budget for both\n",
        "\n",
        "3. **External Data Sources**: Integrate a real API (news, weather, stock prices) and enrich prompts\n",
        "\n",
        "4. **Budget Reset**: Add functionality to reset daily budgets (useful for testing)\n",
        "\n",
        "5. **Cost Comparison**: Compare costs of using OpenAI vs Anthropic for the same tasks"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "consulting",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.13.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}