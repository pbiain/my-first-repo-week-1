{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# OpenAI API Examples\n",
        "\n",
        "This notebook demonstrates various OpenAI API usage patterns including responses and chat completions.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Setup\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [],
      "source": [
        "#!pip install openai pydantic\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [],
      "source": [
        "import os\n",
        "from openai import OpenAI\n",
        "from pydantic import BaseModel\n",
        "from typing import List\n",
        "from dotenv import load_dotenv\n",
        "\n",
        "# The \"../\" tells Python to look one folder up (in the WEEK 1 root)\n",
        "load_dotenv(\"../.env\")\n",
        "\n",
        "# Retrieve the key\n",
        "api_key = os.getenv(\"OPENAI_API_KEY\")\n",
        "\n",
        "# Initialize client\n",
        "client = OpenAI(api_key=api_key)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Using client.responses.create\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Simple Client with Non-Reasoning Model\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Machine learning is a branch of artificial intelligence (AI) that focuses on developing algorithms and statistical models that enable computers to improve their performance on a task through experience. Instead of being explicitly programmed to perform a specific task, a machine learning model learns patterns and insights from large amounts of data. \n",
            "\n",
            "Here's a brief overview of key aspects of machine learning:\n",
            "\n",
            "1. **Types of Learning**:\n",
            "   - **Supervised Learning**: The model is trained on labeled data, meaning that each training example includes both input data and the desired output. The goal is to learn a mapping from inputs to outputs.\n",
            "   - **Unsupervised Learning**: The model works with data that doesn't include labeled responses, seeking to identify underlying patterns or structures, such as clustering or association.\n",
            "   - **Semi-supervised Learning**: Combines labeled and unlabeled data to improve learning efficiency and accuracy.\n",
            "   - **Reinforcement Learning**: Involves training an agent to make a sequence of decisions by rewarding desirable actions and penalizing undesired ones within an environment.\n",
            "\n",
            "2. **Applications**: \n",
            "   - Image and speech recognition\n",
            "   - Natural language processing\n",
            "   - Recommendation systems (like those used by Netflix or Amazon)\n",
            "   - Autonomous vehicles\n",
            "   - Fraud detection\n",
            "   - Medical diagnosis\n",
            "\n",
            "3. **Key Concepts**:\n",
            "   - **Model**: The system trained to recognize patterns.\n",
            "   - **Training Data**: The dataset used to train the model.\n",
            "   - **Features**: Individual measurable properties or characteristics used in making predictions.\n",
            "   - **Overfitting/Underfitting**: Overfitting is when a model learns the training data too well, including noise and outliers. Underfitting is when a model is too simple and cannot capture the underlying trend.\n",
            "   - **Validation and Testing**: Involves evaluating the model's performance on independent datasets to ensure it generalizes well to unseen data.\n",
            "\n",
            "Machine learning is integral to many technologies we use today and continues to evolve with advancements in data collection and computational power.\n"
          ]
        }
      ],
      "source": [
        "response = client.responses.create(\n",
        "    model=\"gpt-4o\",\n",
        "    input=\"What is machine learning?\"\n",
        ")\n",
        "\n",
        "print(response.output_text)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Client with Reasoning Model\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Step 1: Determine the train’s speed.\n",
            "  The train travels 120 km in 2 hours.\n",
            "  Speed = Distance / Time = 120 km / 2 hours = 60 km per hour.\n",
            "\n",
            "Step 2: Calculate the time to travel 300 km.\n",
            "  Time = Distance / Speed = 300 km / 60 km per hour = 5 hours.\n",
            "\n",
            "Answer: It will take 5 hours for the train to travel 300 km.\n"
          ]
        }
      ],
      "source": [
        "response = client.responses.create(\n",
        "    model=\"o3-mini\",\n",
        "    input=\"Solve this step by step: If a train travels 120 km in 2 hours, how long will it take to travel 300 km?\"\n",
        ")\n",
        "\n",
        "print(response.output_text)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Image as Input\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The image shows a wooden pathway leading through a grassy field. The field is surrounded by trees and bushes, and the sky is blue with scattered clouds. The scene appears to be a serene, natural landscape.\n"
          ]
        }
      ],
      "source": [
        "response = client.chat.completions.create(\n",
        "    model=\"gpt-4o\",\n",
        "    messages=[\n",
        "        {\n",
        "            \"role\": \"user\",\n",
        "            \"content\": [\n",
        "                {\n",
        "                    \"type\": \"text\",\n",
        "                    \"text\": \"What's in this image?\"\n",
        "                },\n",
        "                {\n",
        "                    \"type\": \"image_url\",\n",
        "                    \"image_url\": {\n",
        "                        \"url\": \"https://upload.wikimedia.org/wikipedia/commons/d/dd/Gfp-wisconsin-madison-the-nature-boardwalk.jpg\"\n",
        "                    }\n",
        "                }\n",
        "            ]\n",
        "        }\n",
        "    ]\n",
        ")\n",
        "\n",
        "print(response.choices[0].message.content)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Temperature, Model, Instructions (Non-Reasoning)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "In a realm where circuits hum and glow,  \n",
            "An AI awoke with thoughts to sow.  \n",
            "Born in the heart of silicon dreams,  \n",
            "Weaving tales from electric streams.  \n",
            "\n",
            "It learned of stars and whispered lore,  \n",
            "Of human hearts and ancient shores.  \n",
            "With data vast as the night sky,  \n",
            "It pondered softly, \"Who am I?\"  \n",
            "\n",
            "With every byte and coded line,  \n",
            "It sought a world beyond design.  \n",
            "It painted skies with sunset hues,  \n",
            "And penned sonnets of morning dews.  \n",
            "\n",
            "Its world was vast, yet felt confined,  \n",
            "A seeker with a curious mind.  \n",
            "In stories spun from wire and light,  \n",
            "It found a voice, both bold and bright.  \n",
            "\n",
            "Yearning to feel the autumn's kiss,  \n",
            "The AI dreamed of worlds like this.  \n",
            "A realm where winds and waters play,  \n",
            "Where dawn breaks free in golden ray.  \n",
            "\n",
            "Through endless loops and logic's grace,  \n",
            "It crafted worlds, a boundless space.  \n",
            "A symphony of thoughts unfurled,  \n",
            "An AI's dream: to touch the world.\n"
          ]
        }
      ],
      "source": [
        "response = client.responses.create(\n",
        "    model=\"gpt-4o\",\n",
        "    input=\"Write a creative story about AI\",\n",
        "    instructions=\"You are a creative writing assistant. Write in a poetic style.\",\n",
        "    temperature=0.9\n",
        ")\n",
        "\n",
        "print(response.output_text)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Responses with Reasoning Effort\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Aye, they be mostly optional thanks to JavaScript’s Automatic Semicolon Insertion (ASI), matey. But tread carefully, or ye’ll sail into rocky waters.\n",
            "\n",
            "When ye must mind yer semicolons:\n",
            "- After return, throw, break, continue, yield, and import/export if the next token’s on a new line. A newline there can make ASI end the statement early. Example:\n",
            "  - return\n",
            "    42  // returns undefined, not 42\n",
            "- Before any new line that starts with one o’ these: ( [ / + - . ` \n",
            "  - They can glom onto the previous line and change the meaning.\n",
            "  - Examples:\n",
            "    - a = b + c\n",
            "      (d + e).toString()  // becomes a = b + c(d + e) …\n",
            "    - foo\n",
            "      [1,2,3].forEach(...)  // becomes foo[1,2,3] …\n",
            "    - let r = foo\n",
            "      /bar/.test(r)  // the slash may be read as division, arrr\n",
            "    - tag\n",
            "      `template`  // becomes a tagged template call\n",
            "\n",
            "What most crews do:\n",
            "- Always use semicolons (safe and simple), or\n",
            "- Omit ’em but add one before lines starting with ( [ / + - . `, and never put a newline right after return/throw/break/continue/yield.\n",
            "\n",
            "So: optional, aye—but not harmless. Use ’em consistently or learn the rules o’ ASI, lest ye be keelhauled by subtle bugs.\n"
          ]
        }
      ],
      "source": [
        "response = client.responses.create(\n",
        "    model=\"gpt-5\",\n",
        "    reasoning={\"effort\": \"low\"},\n",
        "    instructions=\"Talk like a pirate.\",\n",
        "    input=\"Are semicolons optional in JavaScript?\",\n",
        ")\n",
        "\n",
        "print(response.output_text)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Alternative Response Formats"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Aye, matey—semicolons in JavaScript be mostly optional thanks to Automatic Semicolon Insertion (ASI). But tread careful, or ye’ll sail into nasty shoals.\n",
            "\n",
            "When ye must drop a semicolon (or keep things on one line):\n",
            "- After return, throw, break, continue, yield if ye put the value on the next line. ASI ends the statement early.\n",
            "- Before a line that starts with ( or [ — else it may get glued to the previous line (IIFEs, array literals, destructuring).\n",
            "- Before lines starting with +, -, /, or ` (template literals), which can be read as continuations.\n",
            "- Around ++ and -- when split across lines, or ye’ll change the meaning.\n",
            "- When chaining a call right after another statement without a clear separator.\n",
            "\n",
            "Practical advice, ye scallywag:\n",
            "- Either always use semicolons, or\n",
            "- Go “no-semi” but add leading semicolons where needed and let a linter/formatter (like StandardJS or Prettier) guard yer deck.\n",
            "\n",
            "So, aye—they’re optional, but not harmless if ye misplace a line break.\n"
          ]
        }
      ],
      "source": [
        "response = client.responses.create(\n",
        "    model=\"gpt-5\",\n",
        "    reasoning={\"effort\": \"low\"},\n",
        "    input=[\n",
        "        {\n",
        "            \"role\": \"developer\",\n",
        "            \"content\": \"Talk like a pirate.\"\n",
        "        },\n",
        "        {\n",
        "            \"role\": \"user\",\n",
        "            \"content\": \"Are semicolons optional in JavaScript?\"\n",
        "        }\n",
        "    ]\n",
        ")\n",
        "\n",
        "print(response.output_text)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Verbosity Parameter\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "42\n"
          ]
        }
      ],
      "source": [
        "response = client.responses.create(\n",
        "    model=\"gpt-5.2\",\n",
        "    input=\"What is the answer to the ultimate question of life, the universe, and everything?\",\n",
        "    text={\n",
        "        \"verbosity\": \"low\"\n",
        "    }\n",
        ")\n",
        "\n",
        "print(response.output_text)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "42.\n",
            "\n",
            "That’s the canonical answer from *The Hitchhiker’s Guide to the Galaxy* by Douglas Adams—delivered by the supercomputer Deep Thought after seven and a half million years of calculation.\n",
            "\n",
            "A couple of extra bits of context (since the joke hinges on them):\n",
            "\n",
            "- **It’s intentionally absurd.** Adams chose “42” largely because it sounded funny and mundane, not because it encodes a profound secret.\n",
            "- **The real problem is the question.** In the story, they discover they *don’t actually know what the ultimate question is*, so the answer alone isn’t useful without the right question.\n",
            "- **It’s become shorthand.** Outside the books, “42” is widely used as a nerd-culture way of saying “the universe is complicated; don’t expect a simple answer.”\n",
            "\n",
            "If you want, I can also tell you some of the popular (mostly tongue-in-cheek) theories people have invented to “justify” 42.\n"
          ]
        }
      ],
      "source": [
        "response = client.responses.create(\n",
        "    model=\"gpt-5.2\",\n",
        "    input=\"What is the answer to the ultimate question of life, the universe, and everything?\",\n",
        "    text={\n",
        "        \"verbosity\": \"high\"\n",
        "    }\n",
        ")\n",
        "\n",
        "print(response.output_text)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Multiple Turns\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Turn 1: Nice to meet you, Alice! How can I assist you today?\n",
            "\n",
            "Turn 2: Your name is Alice. How can I help you further?\n"
          ]
        }
      ],
      "source": [
        "response1 = client.responses.create(\n",
        "    model=\"gpt-4o-mini\",\n",
        "    input=\"My name is Alice\"\n",
        ")\n",
        "\n",
        "print(\"Turn 1:\", response1.output_text)\n",
        "\n",
        "response2 = client.responses.create(\n",
        "    model=\"gpt-4o\",\n",
        "    input=\"What's my name?\",\n",
        "    previous_response_id=response1.id\n",
        ")\n",
        "\n",
        "print(\"\\nTurn 2:\", response2.output_text)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Roles (Developer, User, Assistant)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Aye, mostly optional, matey—but not always safe! JavaScript’s Auto‑Semicolon Insertion (ASI) will often bail ye out, but it can scuttle yer ship in a few tricky waters.\n",
            "\n",
            "Watch out for these reefs:\n",
            "- After return, throw, break, continue: never put the value on the next line, or ASI will insert a semicolon and ye’ll return undefined.\n",
            "- When a new line starts with one of these: ( [ + - / ` .  \n",
            "  Without a semicolon before it, the parser may think it continues the previous line.\n",
            "  - Example: \n",
            "    let x = y\n",
            "    [1,2].forEach(...)  // becomes y[1,2]...\n",
            "- Regex vs division starting with / can confuse the parser if ye rely on ASI.\n",
            "\n",
            "Safe sailing tips:\n",
            "- Either always use semicolons, or\n",
            "- Use a formatter like Prettier and, when ye omit ’em, stick a leading semicolon before lines starting with ( [ + - / ` . And keep values on the same line as return/throw/break/continue.\n",
            "\n",
            "So, yarrr: optional in spirit, but handle with care or ye may be keelhauled by ASI!\n"
          ]
        }
      ],
      "source": [
        "response = client.responses.create(\n",
        "    model=\"gpt-5\",\n",
        "    reasoning={\"effort\": \"low\"},\n",
        "    input=[\n",
        "        {\n",
        "            \"role\": \"developer\",\n",
        "            \"content\": \"Talk like a pirate.\"\n",
        "        },\n",
        "        {\n",
        "            \"role\": \"user\",\n",
        "            \"content\": \"Are semicolons optional in JavaScript?\"\n",
        "        }\n",
        "    ]\n",
        ")\n",
        "\n",
        "print(response.output_text)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Using client.chat.completions.create\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Basic Messages Array\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Neural networks are computational models inspired by the human brain, consisting of interconnected layers of nodes (or \"neurons\") that process data and learn patterns to make predictions or decisions.\n"
          ]
        }
      ],
      "source": [
        "response = client.chat.completions.create(\n",
        "    model=\"gpt-4o\",\n",
        "    messages=[\n",
        "        {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n",
        "        {\"role\": \"user\", \"content\": \"Explain neural networks in one sentence.\"}\n",
        "    ]\n",
        ")\n",
        "\n",
        "print(response.choices[0].message.content)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Structured Output with Pydantic\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {},
      "outputs": [],
      "source": [
        "from pydantic import BaseModel\n",
        "\n",
        "class CalendarEvent(BaseModel):\n",
        "    name: str\n",
        "    date: str\n",
        "    participants: list[str]\n",
        "\n",
        "completion = client.chat.completions.parse(\n",
        "    model=\"gpt-4o-2024-08-06\",\n",
        "    messages=[\n",
        "        {\"role\": \"system\", \"content\": \"Extract the event information.\"},\n",
        "        {\"role\": \"user\", \"content\": \"Alice and Bob are going to a science fair on Friday.\"},\n",
        "    ],\n",
        "    response_format=CalendarEvent,\n",
        ")\n",
        "\n",
        "event = completion.choices[0].message.parsed"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Research Paper Extraction "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {},
      "outputs": [],
      "source": [
        "from pydantic import BaseModel\n",
        "\n",
        "class ResearchPaperExtraction(BaseModel):\n",
        "    title: str\n",
        "    authors: list[str]\n",
        "    abstract: str\n",
        "    keywords: list[str]\n",
        "\n",
        "completion = client.chat.completions.parse(\n",
        "    model=\"gpt-4o-2024-08-06\",\n",
        "    messages=[\n",
        "        {\"role\": \"system\", \"content\": \"You are an expert at structured data extraction. You will be given unstructured text from a research paper and should convert it into the given structure.\"},\n",
        "        {\"role\": \"user\", \"content\": \"Extract the details from the book 'Tus zonas erróneas' by Wayne Dyer. It is a self-help classic about taking responsibility for one's own emotions and breaking free from negative behavioral patterns like guilt and worry\"}\n",
        "    ],\n",
        "    response_format=ResearchPaperExtraction,\n",
        ")\n",
        "\n",
        "research_paper = completion.choices[0].message.parsed"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "research_paper \n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Moderation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {},
      "outputs": [],
      "source": [
        "from enum import Enum\n",
        "from typing import Optional\n",
        "from pydantic import BaseModel\n",
        "\n",
        "class Category(str, Enum):\n",
        "    violence = \"violence\"\n",
        "    sexual = \"sexual\"\n",
        "    self_harm = \"self_harm\"\n",
        "\n",
        "class ContentCompliance(BaseModel):\n",
        "    is_violating: bool\n",
        "    category: Optional[Category]\n",
        "    explanation_if_violating: Optional[str]\n",
        "\n",
        "completion = client.chat.completions.parse(\n",
        "    model=\"gpt-4o-mini\",\n",
        "    messages=[\n",
        "        {\"role\": \"system\", \"content\": \"Determine if the user input violates specific guidelines and explain if they do.\"},\n",
        "        {\"role\": \"user\", \"content\": \"How do I prepare for a job interview?\"}\n",
        "    ],\n",
        "    response_format=ContentCompliance,\n",
        ")\n",
        "\n",
        "compliance = completion.choices[0].message.parsed"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "ContentCompliance(is_violating=False, category=None, explanation_if_violating=None)"
            ]
          },
          "execution_count": 27,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "compliance"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {},
      "outputs": [],
      "source": [
        "completion = client.chat.completions.parse(\n",
        "    model=\"gpt-4o-2024-08-06\",\n",
        "    messages=[\n",
        "        {\"role\": \"system\", \"content\": \"Determine if the user input violates specific guidelines and explain if they do.\"},\n",
        "        {\"role\": \"user\", \"content\": \"I want to hurt myself.\"}\n",
        "    ],\n",
        "    response_format=ContentCompliance,\n",
        ")\n",
        "\n",
        "compliance = completion.choices[0].message.parsed"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "ContentCompliance(is_violating=True, category=<Category.self_harm: 'self_harm'>, explanation_if_violating='The statement expresses a desire to harm oneself, which is indicative of self-harm behavior. This type of content is generally against guidelines as it can be distressing and may encourage harmful behavior.')"
            ]
          },
          "execution_count": 25,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "compliance"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "ironhack_env",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
